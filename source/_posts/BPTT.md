---
title: Backpropogation Through Time
date: 2021-11-26 17:57:53
tags:  [RNN, ML, BPTT]
categories: Machine Learning
katex: true
description: BPTT formula derivation
---

![BPTT](/images/BPTT/cover.png)

<!--more-->

# Foreword
ç½‘ä¸Šçœ‹äº†æŒºå¤šBPTTä¸­æ–‡æ•™ç¨‹ï¼Œæ„Ÿè§‰äº‘é‡Œé›¾é‡Œã€‚åæ¥çœ‹äº†æ²¹ç®¡ä¸Šçš„ä¸¤ä½ä¸‰å“¥çš„è®²è§£ï¼Œæ„Ÿè§‰ååˆ†é€šé€ã€‚ç©¶ç«Ÿæ˜¯æˆ‘ä¸­æ–‡æ°´å¹³é€€åŒ–ï¼Œè¿˜æ˜¯æœç´¢çš„å§¿åŠ¿ä¸å¯¹ï¼ŸğŸ˜…

I read a lot of Chinese tutorials online about BPTT, but unfortunately, they all made me lost. Things changed until I saw two tutorial videos  on YouTube made by Indian, which are quite clear and insightful. I wonder is it due to my degrading Chinese, or due to my incorrect searching way?

# PDF
[Click here](/notebook/BPTT.pdf)

# Reference
1. [Training RNNs - Loss and BPTT](https://www.youtube.com/watch?v=RrB605Mbpic)
2. [Deep Learning 64: (Part B) Backpropgtation in Time (BPTT) for Recurrent Neural Network (RNN)](https://www.youtube.com/watch?v=phOVApJHjsU)
